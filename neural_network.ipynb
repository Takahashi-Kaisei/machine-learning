{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "中間層が存在し，ネットワークが三層以上の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "from IPython.display import HTML\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from schemdraw.parsing import logicparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "複数の入力をまとめて処理することはミニバッチ処理と呼ばれる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chapter1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークでは一層目から二層目のつながりを以下のように表せる．\n",
    "$$\n",
    "a^{1} = \\sigma(Wa^{0}+b)\n",
    "$$\n",
    "このとき$W$は重みの行列であり，$b$はバイアス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3344101788.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    def feedforward(self, a):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a)+b)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sigmoid関数は古い．訓練しづらかった．\n",
    "\n",
    "ReLUの方が上手くいくしよく使用される．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chpter2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欲しい物はアルゴリズム\\\n",
    "どのようなものか，13002の重みとバイアスを適切に調整するようなアルゴリズム．\\\n",
    "(入力784，二層目16，三層目16，出力10のニューラルネットワーク)\n",
    "\n",
    "---\n",
    "\n",
    "重みはニューロンのつながりの強さ，バイアスはアクティベーションしがちかどうか．\n",
    "\n",
    "コスト関数(目的関数)は入力が13002で出力が1つ(コスト)で大量のパラメータ\n",
    "\n",
    "これは考えることがいっぱい...\n",
    "\n",
    "モデルのダメさを言うだけじゃなくて，どのように改善したら良いか教えてあげないとね．\\\n",
    "いつもは解析的に最小二乗で極小の点を求めることができたけど，入力が13002と複雑な今の問題では到底できないよ．\n",
    "\n",
    "でも最小にしたい関数は複雑で，異なる極小点はとってしまうかもしれない．\n",
    "\n",
    "傾きを考える前に方向を考える．\\\n",
    "その方向っていうのが勾配のこと．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
