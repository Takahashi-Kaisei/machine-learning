{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "勾配法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最急降下法(勾配法)\n",
    "$$\n",
    "\\bm{x}^{(t+1)} = \\bm{x}^{(t)} - \\eta_t \\nabla f(\\bm{x}^{(t)})\n",
    "$$\n",
    "$\\bm{x}$が多次元のときはテーラー展開を考える"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.array([[1, 3], [3, 6], [6, 5], [8, 7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 10000\n",
    "eta = 0.001\n",
    "eps = 1e-4\n",
    "\n",
    "X = np.vstack([D[:,0], np.ones_like(D[:,0])]).T #二列目は1\n",
    "y = D[:,1]\n",
    "w = np.zeros(X.shape[1]) #Xの列数，ようはXの次元数\n",
    "\n",
    "for t in range(max_epochs):\n",
    "    y_hat = X @ w\n",
    "    grad = 2 * X.T @ (y_hat - y) #目的関数の勾配\n",
    "    if np.sum(np.abs(grad)) < eps: #決めた値を勾配が下回っているかどうか\n",
    "        break\n",
    "    w -= eta * grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43104138, 3.31030308])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5464"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで問題なくwを求められるがt(回数)が多すぎる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確率的勾配降下法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目的関数が凸関数ではない場合、例えば多層ニューラルネットワークの学習では学習率そのものがハイパーパラメータ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
