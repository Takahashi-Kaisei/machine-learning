E(w)を最小にするwがほしい．
$\nabla E(w) = 0$を解く．
# (解析的に解けないので)ニュートン法を使う．
## 二階微分の意味
### $\nabla E(w)$の接線
### 曲率の情報
ヘッセ行列は、関数の曲率を捉えるための重要なツールです。
多変数関数の曲率は各方向の2次微分で表されますが、ヘッセ行列はこれを包括的にまとめたものです。具体的に、

正定値のヘッセ行列は、関数が局所的に凸であることを示します。
負定値のヘッセ行列は、関数が局所的に凹であることを示します。
不定値のヘッセ行列は、鞍点の存在を示唆します（局部最小にも局部最大にもならない点）。
#### 曲率とは
曲線や，曲面での，特定の点における曲がり具合を定量的に表す．
#### 曲率が与える情報
曲線や，曲面での，特定の点における曲がり具合，どのくらい更新すれば良いのかという情報を与える．

曲率が高いということ．(ヘッセ行列の固有値が高い)
→関数が急激に変化するのでステップサイズが小さくなる．．

##### 現在の値(w)で，ヘッセ行列を計算する．
現在の値，現在の点での曲率と，更新方向がわかる．

##### ヘッセ行列を固有分解
$ H(w_k) ) を ( H(w_k) = Q \Lambda Q^T $ の形で固有分解する．

固有値 (( \lambda )): 行列 ( H ) のある方向に対しての「伸び率」として表現されるスカラー。
→ここが曲率の情報を持っている．伸び率
固有ベクトル (( \mathbf{v} )): 行列 ( H ) によって伸びる方向のベクトル。
→ここが更新の方向を示している．

固有分解の方法については飛ばす．
- 固有値が曲率，どれだけ更新するかの情報を持っている．
- 固有ベクトルが更新の方向の情報を持っている．

##### 更新ステップの計算：preview

勾配 (\nabla E(w_k)) を固有ベクトルの基底に変換し、各基底での値を固有値の逆数でスケールします。
次に、固有ベクトルの基底から元の空間に変換し直すことで、新しいステップ方向とステップサイズを得ます。
→わからん

具体例

二次元の例を用いて説明します。次のような関数 ( E(w) ) を考えましょう：
$ E(w) = \frac{1}{2} w^T H w $
ここで、簡単のためにヘッセ行列 ( H ) を以下とします：
$ H = \begin{pmatrix} 3 & 1 \\ 1 & 3 \end{pmatrix} $

初期点を $ w_k = \begin{pmatrix} 1 \\ 1 \end{pmatrix} $ とします。

ステップ 1. 勾配の計算
関数 $ E(w) $ の勾配 $ \nabla E(w_k) $ を計算します。
$ \nabla E(w_k) = H w_k = \begin{pmatrix} 3 & 1 \\ 1 & 3 \end{pmatrix} \begin{pmatrix} 1 \\ 1 \end{pmatrix} = \begin{pmatrix} 4 \\ 4 \end{pmatrix} $

ステップ 2. ヘッセ行列の固有分解
次に、ヘッセ行列 $ H $ を固有分解します。
$ H = Q \Lambda Q^T $

まず、固有値を求めます。特性方程式から固有値を求めます。
$ \det(H - \lambda I) = 0 $
つまり、
$ \begin{vmatrix} 3 - \lambda & 1 \\ 1 & 3 - \lambda \end{vmatrix} = (3 - \lambda)^2 - 1 = 0 $
$
\lambda^2 - 6\lambda + 8 = 0 \quad \Rightarrow \quad (\lambda - 4)(\lambda - 2) = 0
$
したがって、固有値は $ \lambda_1 = 4 $ と $ \lambda_2 = 2 $ です。

次に、対応する固有ベクトルを求めます。

$ \lambda_1 = 4 $
$
(H - 4I)\mathbf{v}_1 = 0 \quad \Rightarrow \quad \begin{pmatrix} -1 & 1 \\ 1 & -1 \end{pmatrix} \begin{pmatrix} v_{11} \\ v_{12} \end{pmatrix} = 0
$
よって、固有ベクトル $ \mathbf{v}_1 = \begin{pmatrix} 1 \\ 1 \end{pmatrix} $

$ \lambda_2 = 2 $
$
(H - 2I)\mathbf{v}_2 = 0 \quad \Rightarrow \quad \begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix} \begin{pmatrix} v_{21} \\ v_{22} \end{pmatrix} = 0
$
よって、固有ベクトル $ \mathbf{v}_2 = \begin{pmatrix} 1 \\ -1 \end{pmatrix} $

固有ベクトルを正規化し、
$ Q = \frac{1}{\sqrt{2}} \begin{pmatrix} 1 & 1 \\ 1 & -1 \end{pmatrix} $
$ \Lambda = \begin{pmatrix} 4 & 0 \\ 0 & 2 \end{pmatrix} $

ステップ 3. 勾配を固有ベクトルの基底に変換
勾配 $\nabla E(w_k)$ を固有ベクトルの基底に変換します。固有ベクトルの基底 $ Q $ に変換するために、$ Q^T $ を用います。
$ \mathbf{g}_Q = Q^T \nabla E(w_k) = \frac{1}{\sqrt{2}} \begin{pmatrix} 1 & 1 \\ 1 & -1 \end{pmatrix} \begin{pmatrix} 4 \\ 4 \end{pmatrix} = \frac{1}{\sqrt{2}} \begin{pmatrix} 8 \\ 0 \end{pmatrix} = \begin{pmatrix} 4\sqrt{2} \\ 0 \end{pmatrix} $

ステップ 4. スケール変換
固有値の逆数でスケールします。
$ \Lambda^{-1} = \begin{pmatrix} \frac{1}{4} & 0 \\ 0 & \frac{1}{2} \end{pmatrix} $
$ \mathbf{d}_Q = \Lambda^{-1} \mathbf{g}_Q = \begin{pmatrix} \frac{1}{4} & 0 \\ 0 & \frac{1}{2} \end{pmatrix} \begin{pmatrix} 4\sqrt{2} \\ 0 \end{pmatrix} = \begin{pmatrix} \sqrt{2} \\ 0 \end{pmatrix} $

ステップ 5. 基底変換と更新
固有ベクトルの基底から元の空間へ戻すには、再び ( Q ) を用います。
$ \Delta w_k = Q \mathbf{d}_Q = \frac{1}{\sqrt{2}} \begin{pmatrix} 1 & 1 \\ 1 & -1 \end{pmatrix} \begin{pmatrix} \sqrt{2} \\ 0 \end{pmatrix} = \frac{1}{\sqrt{2}} \begin{pmatrix} \sqrt{2} \\ \sqrt{2} \end{pmatrix} = \begin{pmatrix} 1 \\ 1 \end{pmatrix} $

新しい点 $ w_{k+1} $ は、
$ w_{k+1} = w_k - \Delta w_k = \begin{pmatrix} 1 \\ 1 \end{pmatrix} - \begin{pmatrix} 1 \\ 1 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix} $

まとめ
この例に基づいて、以下のステップで更新ステップを計算する方法を理解できます：

勾配の計算：$\nabla E(w_k)$
ヘッセ行列の固有分解：$H = Q \Lambda Q^T$
勾配を固有ベクトルの基底に変換：$\mathbf{g}_Q = Q^T \nabla E(w_k)$
スケール変換：固有値の逆数でスケール $\mathbf{d}_Q = \Lambda^{-1} \mathbf{g}_Q$
更新ステップの計算：基底変換と更新 $\Delta w_k = Q \mathbf{d}_Q$
新しい点の計算：$w_{k+1} = w_k - \Delta w_k$


#### ヘッセ行列のどこが曲率の情報なのか
- 曲率：ヘッセ行列の固有値
- 更新の方向：固有ベクトル

ヘッセ行列が非常に高い特異値（つまり、高い曲率）を持つ場合、その特異方向でのステップサイズは自然に小さくなります。
→曲率が高いということは，少しのステップで大きく更新されるということだから，ステップサイズは小さくなる．


### 凸性の確認
関数が凸であるかどうかを確認するのが重要です。ヘッセ行列が正定値であれば、その関数が凸であることを示します。これにより、求められた極値が大域的最小値であることを保証することができます。
→その点においての凸性を確認するのに大域的な最小値がわかるの？


凸性の確認と重要性
最適化問題を扱う際、関数が凸（convex）であるかどうかを確認することは極めて重要です。凸関数の最適化においては、局所的な最小値が大域的な最小値でもあるという重要な特性があるためです。
→最小値ではない局所解がある時，それは凸関数ではないということ？
　でも実際にそんな場面はたくさんあるよね．

関数の凸性とは
関数 $f$ が凸であるとは、下記の条件を満たすときに言います：

- 集合の説明：$\forall x, y \in \text{dom}(f)$

(fの定義域の任意の点xとyに対して、この条件が成り立つ必要があるという意味)

- パラメータの範囲：$\forall \theta \in [0, 1]$

(0から1の間の全ての実数をとる．0と1の間の任意の凸結合（重み付き平均）を考慮するという意味)

- 凸結合：$f(\theta x + (1 - \theta)y) \leq \theta f(x) + (1 - \theta)f(y) \quad $

($\theta x + (1 - \theta)y$は点xと点yの間の凸結合．単にxとyを$\theta$と$1-\theta$の比率で混ぜ合わせた点を指す．具体的には$\theta$の値のに応じてxとyを線形に補完した点になる．)

- 不等式の構成：$f(\theta x + (1 - \theta)y) \leq \theta f(x) + (1 - \theta)f(y) \quad$

左辺 $ f(\theta x + (1 - \theta)y) $ は、点 $ \theta x + (1 - \theta)y $ における関数 $ f $ の値．
右辺 $ \theta f(x) + (1 - \theta)f(y) $ は、点 $ x $ における関数 $ f $ の値と点 $ y $ における関数 $ f $ の値の重み付き平均．

- 凸関数の直感的理解

この不等式が示しているのは、関数 $ f $ のグラフ上の任意の二点 $ (x, f(x)) $ と $ (y, f(y)) $を互いに直線で結ぶと、その直線が関数のグラフの上に来る、すなわち、関数のグラフが直線よりも下方で（または直線と一致して）凸であるということ．

言い換えると、関数 $ f $ は以下の性質を持つことを示しています：

凹みがなく、滑らかに上向きに曲がっているか直線である（つまり、局所的な最小値が大域的な最小値である）．
具体例での確認
これを具体的な例で確認してみル．例えば，関数 $ f(x) = x^2 $ を考える．

$ x = 1 $, $ y = 3 $, $ \theta = 0.5 $ で試してみる．：
$
\theta x + (1-\theta)y = 0.5 \cdot 1 + 0.5 \cdot 3 = 2
$
$
f(\theta x + (1 - \theta)y) = f(2) = 2^2 = 4
$
$
\theta f(x) + (1 - \theta)f(y) = 0.5 \cdot 1^2 + 0.5 \cdot 3^2 = 0.5 + 4.5 = 2.5
$
この例では、
$ f(2) = 4 $
に対し、
$ 0.5 f(1) + 0.5 f(3) = 2.5 $

だから，不等式が成り立つ：$ 4 \leq 4 $
※ 0から1の全ての$\theta$でこれが成り立つ．

このように，関数 $ f(x) = x^2 $ は凸関数であることが確認できる．

ここで、$\theta$ は0から1の間の実数．
直感的には，関数のグラフが直線で下に膨らんでいる．（すなわち、直線を引いたときにその線が関数のグラフの上側に位置する）ことを意味する．

- ヘッセ行列を用いた凸性の確認

凸性を確認する方法の一つとしてヘッセ行列（関数の二階微分行列）を用いることがあり、これを以下に詳述します：

ヘッセ行列の定義
ヘッセ行列 $H$ は各変数に対する二階微分を含む行列です。具体的には、関数 $ f : \mathbb{R}^n \to \mathbb{R} $ に対して、ヘッセ行列 $ H $ は以下のように定義される．：
$
H = \begin{pmatrix}
\frac{\partial^2 f}{\partial x_1^2} & \frac{\partial^2 f}{\partial x_1 \partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
\frac{\partial^2 f}{\partial x_2 \partial x_1} & \frac{\partial^2 f}{\partial x_2^2} & \cdots & \frac{\partial^2 f}{\partial x_2 \partial x_n} \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1} & \frac{\partial^2 f}{\partial x_n \partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_n^2}
\end{pmatrix}
$

ヘッセ行列の正定値性

関数 $ f $ が凸であるための必要かつ十分な条件は、そのヘッセ行列 $ H $ が常に正定値（positive definite）であることです。正定値であるとは、任意の非ゼロベクトル $ z \in \mathbb{R}^n $ に対して次の条件が成り立つことを意味します：
$
z^T H z > 0
$

正定値性の確認方法
具体的には、ヘッセ行列の固有値を用いて正定値性を確認することが一般的です。ヘッセ行列 ( H ) の全ての固有値が正である場合、 ( H ) は正定値行列であり、関数は凸です。

固有値の計算：
ヘッセ行列 $ H $ の固有値 $ \lambda_1, \lambda_2, \ldots, \lambda_n $ を求めます。

固有値の確認：
すべての固有値が正であることを確認します（すなわち、 $ \lambda_i > 0 $ であること）。

これにより、関数が凸であることを保証できます。

具体例
次に、具体例を通してこのプロセスを説明します。

例 ： 二変数関数
関数 $ f(x, y) = x^2 + y^2 $ について考えましょう。この関数が凸であることを確認します。

ヘッセ行列の計算：
$ f $ のヘッセ行列は次のようになります：
$
H = \begin{pmatrix}
\frac{\partial^2 f}{\partial x^2} & \frac{\partial^2 f}{\partial x \partial y} \\
\frac{\partial^2 f}{\partial y \partial x} & \frac{\partial^2 f}{\partial y^2}
\end{pmatrix}
= \begin{pmatrix}
2 & 0 \\
0 & 2
\end{pmatrix}
$
対角成分について，11はxに関する2階微分，22はyに関する2階微分．
12と21はxとyの混合偏微分なので0になる．

固有値の計算と確認：
ヘッセ行列 $ H $ の固有値は容易に計算できます。行列 $ H $ は対角行列なので、固有値は対角成分そのものです。したがって、固有値は $ \lambda_1 = 2 $ と $ \lambda_2 = 2 $ です。

固有値の確認：
すべての固有値 $ 2 $ は正です。従って、ヘッセ行列 $ H $ は正定値であり、関数 $ f(x, y) = x^2 + y^2 $ は凸です。

凸性の重要性
関数が凸である場合、その最小値は以下の特性を持つ：

大域的最小値：凸関数の局所的最小値は大域的最小値でもあります。この性質により最適化プロセスが大いに簡略化されます。
アルゴリズムの収束性：凸関数に対する最適化アルゴリズムは、非凸関数に比べて収束性が高く、理論的に保証されている場合が多いです。
総括
ヘッセ行列の正定値性の確認：固有値を計算し、すべてが正であることを確認する。
凸性の確認：これにより、関数の最適化における安定性と収束性が保証され、得られた最小値が大域的最小値であることが確認される。
関数の凸性を確認することは、最適化問題を解く上での基礎として非常に重要であり、この確かさがあることで得られる最適解の信頼性も高まります。ヘッセ行列の特性を利用することで、関数の凸性の確認を効率的かつ信頼性の高い方法で行うことができます。

- おまけ

ニュートン法のような数値的アルゴリズムを考えた時，パラメータwは更新されていくので，その時のwの値の関数の性質は分かっても，更新された後の関数の性質はわからないはずです，
ヘッセ行列は，逐一更新されるwに対して，その時の関数の性質を求めるような行列という認識で間違いないですか？
→あなたの理解は正しいです。ニュートン法や同様の数値的アルゴリズムにおいて、ヘッセ行列は逐次的に更新されるパラメータ ( w ) 各々に対して計算され、その時点での関数の性質を示します。この逐次更新がアルゴリズムの収束性と精度に寄与します。


$\begin{pmatrix} x_{k+1} \\ y_{k+1} \end{pmatrix} = \begin{pmatrix} x_k \\ y_k \end{pmatrix} - \begin{pmatrix} \frac{1}{20} & 0 \\ 0 & \frac{1}{2} \end{pmatrix} \begin{pmatrix} 20x_k \\ 2y_k \end{pmatrix} = \begin{pmatrix} x_k - x_k \\ y_k - y_k \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}$


勾配には，更新方向の情報しか含まれておらず，どのくらい更新するのかという情報は含まれていない．
その情報を与えるのが固有値であり，固有ベクトルは，曲率の方向を示す．
曲率の方向とは
→各パラメータ方向の曲率を示す．こっちのパラメータの方向は曲率が高いよ，とか低いよ．とか...
 それを元に，どのくらい更新するかを固有値で決め，勾配方向に更新する．その際に，固有ベクトルと固有値が，この方向はどのくらいの曲率であるよ．だからステップサイズはどのくらいね．って情報を与える．


ヘッセ行列で凸性を確認することは，ニュートン法においてどのような役割を果たすのですか？
数値的アルゴリズムであれば，人間が凸性を逐一確認することはないので，凸性を確認するのは無駄に思えます．単に固有値を算出した時に，おまけでわかるのが凸性という認識でしょうか？
→おまけ，とい解釈でOK．ロジスティック回帰における損失関数(負の対数尤度関数)は，凸関数であることが保証されているため，凸最適化問題と捉えられ，ニュートン法による数値的アルゴリズムで問題なく収束する．
 しかし，一般的に対数尤度が凸関数であるというわけじゃなく，混合ガウスモデルなどでは，凸関数ではないので，別のアプローチが用いられる．
→ちなみに，凸関数でない場合，以下のようなアプローチが考えられる．

事前確認：経験的に、関数が凸であることがわかっている場合や、凸関数のクラスに属する問題を扱う場合には、それを前提としてニュートン法が使えます。
途中での確認：実行中には、数値的にヘッセ行列の正定値性が失われている場合（例えば、固有値の一つが負になる場合）、向きの判断が不安定になることがあります。この場合、ダンピング因子（学習率の調整）を用いるなどのロバスト化技法が使われます（レーベンバーグ-マルカルト法など）。
凸性の確認が直接的な役割を果たす例：

学習率の適応的調整：ニュートン法に基づいたアルゴリズムで、正定値性が保たれていない場合、学習率を調整することで頑健性を増す手法が存在します。これには、負の固有値を考慮した修正やダンピングを行うことが含まれます。
分岐の検出：複数の最小値が存在する場合、凸性の確認は局所的最小値に陥るリスクを減らすための手段として使われることがあります。

### 条件数による計算の安定性評価
ヘッセ行列の条件数（最大特異値と最小特異値の比）は、最適化計算の安定性や収束速度に影響します。
条件数が高いと、最適化アルゴリズムが不安定になる可能性があり、収束が遅くなることもあります。
→条件数とは
→特異値とは
→最適化計算の安定性とは？
→収束速度は何によってきまる？
→条件数が高いと，最適化アルゴリズムが不安定になる理由は？

結構重そうなので飛ばす

### 特異値分解による方向性情報
ヘッセ行列の特異値分解は、関数が最も速く変化する方向（主方向）や、最も遅く変化する方向（副方向）を提供します。
これにより、最適化の際にどの方向に調整を加えるべきかがわかります。
主成分分析（PCA）などの次元削減技術にも同様の原理がここにあります。

#### 特異値分解とは
固有値分解がnxnの正方行列に対して行われるのに対し，特異値分解はm×nの行列に対して行われる．

#### ヘッセ行列では
ヘッセ行列はn×nの正方行列なので，固有値分解が行われる．
特異値分解は必要に応じて特定の目的（例えば数値的な安定性の確認や非対称性の解析）に使用される．

### 二次近似
ヘッセ行列を使うことで、関数を局所的に二次近似でき、それに基づいてより精度の高い解を導けます。
テイラー展開の二次項までを考慮すると、関数の形状をより正確に捉えることができます。

$ f(\mathbf{x}) \approx f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} - \mathbf{x}_0) + \frac{1}{2} (\mathbf{x} - \mathbf{x}_0)^T H(\mathbf{x}_0)(\mathbf{x} - \mathbf{x}_0)$


関数 $ f(x) $ を点 $ x_0 $ の周りで二次近似する場合、テイラー展開は次のようになります：

$ f(x) \approx f(x_0) + f'(x_0)(x - x_0) + \frac{1}{2} f''(x_0)(x - x_0)^2 $

例えば、関数が $ f(x) = x^2 $ で $ x_0 = 1 $ のとき：

$ f(x) = x^2 $
$ f(1) = 1 $
$ f'(x) = 2x \Rightarrow f'(1) = 2 $
$ f''(x) = 2 \Rightarrow f''(1) = 2 $

この場合、二次近似は：

$ f(x) \approx 1 + 2(x - 1) + \frac{1}{2} \cdot 2 \cdot (x - 1)^2 = 1 + 2(x - 1) + (x - 1)^2 $

これは二次関数 $ f(x) = x^2 $ が放物線であることを示します。


多変数関数の二次近似
例えば、二変数関数 $ f(x, y) = x^2 + y^2 $ を点 $ \mathbf{x}_0 = (1, 1) $ の周りで二次近似する場合：

関数値：
$ f(1, 1) = 1^2 + 1^2 = 2 $

一階微分（勾配ベクトル）：
$ \nabla f(\mathbf{x}) = \begin{pmatrix} \frac{\partial f}{\partial x} \\ \frac{\partial f}{\partial y} \end{pmatrix} = \begin{pmatrix} 2x \\ 2y \end{pmatrix} \Rightarrow \nabla f(1, 1) = \begin{pmatrix} 2 \\ 2 \end{pmatrix} $

二階微分（ヘッセ行列）：
$ H(\mathbf{x}) = \begin{pmatrix} \frac{\partial^2 f}{\partial x^2} & \frac{\partial^2 f}{\partial x \partial y} \\ \frac{\partial^2 f}{\partial y \partial x} & \frac{\partial^2 f}{\partial y^2} \end{pmatrix} = \begin{pmatrix} 2 & 0 \\ 0 & 2 \end{pmatrix} \Rightarrow H(1, 1) = \begin{pmatrix} 2 & 0 \\ 0 & 2 \end{pmatrix} $

二次近似の式は：

$ f(x, y) \approx 2 + \begin{pmatrix} 2 \\ 2 \end{pmatrix}^T \begin{pmatrix} x - 1 \\ y - 1 \end{pmatrix} + \frac{1}{2} \begin{pmatrix} x - 1 \\ y - 1 \end{pmatrix}^T \begin{pmatrix} 2 & 0 \\ 0 & 2 \end{pmatrix} \begin{pmatrix} x - 1 \\ y - 1 \end{pmatrix} $

簡略化すると、

$ f(x, y) \approx 2 + 2(x - 1) + 2(y - 1) + (x - 1)^2 + (y - 1)^2 $

これは放物面を表します。

二次近似をわかりやすく可視化したのは，[この記事](https://automatic-browsing.com/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%88%E3%83%B3%E6%B3%95%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E5%8F%8E%E6%9D%9F%E3%81%97%E3%81%A6%E3%81%84%E3%81%8F%E3%81%AE%E3%81%8B-1%E5%A4%89/)が参考になるので，こちらを参照してほしい．

自分は限界

### 鞍点の検出
損失関数の最小点ではなくサドルポイント（鞍点）に収束しないように注意しなければならない場合があります。
ヘッセ行列を用いると、特異値分解を通じてどのような点に到達しているのかを正しく判断できます。

→ヘッセ行列を固有値分解し，固有値をみることで，鞍点を検出することができる．
 具体的には，固有値が正と負を持つ場合，その点は鞍点である．固有値が正のみか負のみであれば，極値である．と言える．(固有値0は判定が不確かな可能性が高い．)
 しかし，今回実装する普通のニュートン法では鞍点に対処するような処理はできていないので，鞍点に収束，発散する可能性がある．(この表現が正かはわからない．)
 それに対処しているのが準ニュートン法などのアルゴリズムである．
